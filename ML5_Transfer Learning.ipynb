{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ff0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, decode_predictions\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b04f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c76023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bear', 'Bird', 'Cat', 'Cow', 'Deer', 'Dog', 'Dolphin', 'Elephant', 'Giraffe', 'Horse', 'Kangaroo', 'Lion', 'Panda', 'Tiger', 'Zebra']\n",
      "Bear\n",
      "Bird\n",
      "Cat\n",
      "Cow\n",
      "Deer\n",
      "Dog\n",
      "Dolphin\n",
      "Elephant\n",
      "Giraffe\n",
      "Horse\n",
      "Kangaroo\n",
      "Lion\n",
      "Panda\n",
      "Tiger\n",
      "Zebra\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random \n",
    "folder_path = r\"dataset/animal_data/\" # Put the path to your dataset\n",
    "ratio_train = .8 # Ratio of images in the train dataset\n",
    "\n",
    "directories = [name for name in os.listdir(folder_path) \n",
    "               if os.path.isdir(os.path.join(folder_path, name))]\n",
    "\n",
    "directories.pop(-1)\n",
    "directories.pop(-1)\n",
    "print(directories)\n",
    "\n",
    "\n",
    "for dir in directories: \n",
    "    print(dir)\n",
    "    src_dir = folder_path+dir\n",
    "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "    n_files = len(files)\n",
    "    train_size = round(ratio_train * n_files)\n",
    "    idx_train = random.sample(range(n_files), train_size)\n",
    "    idx_test = list(set(range(n_files)) - set(idx_train))\n",
    "    dst_dir = folder_path+'_train/'+dir+'/'\n",
    "\n",
    "# Make sure destination folder exists\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Loop over selected indices and copy files\n",
    "    for idx in idx_train:\n",
    "        file_name = files[idx]\n",
    "        src_path = os.path.join(src_dir, file_name)\n",
    "        dst_path = os.path.join(dst_dir, file_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    dst_dir = folder_path+'_test/'+dir+'/'\n",
    "\n",
    "# Make sure destination folder exists\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "# Loop over selected indices and copy files\n",
    "    for idx in idx_test:\n",
    "        file_name = files[idx]\n",
    "        src_path = os.path.join(src_dir, file_name)\n",
    "        dst_path = os.path.join(dst_dir, file_name)\n",
    "        shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cbd4c9",
   "metadata": {},
   "source": [
    "dataloading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed7dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1919 images belonging to 15 classes.\n",
      "Found 905 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    #rescale=1/255.0,\n",
    "    rotation_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    directory=r\"dataset/animal_data/_train/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=128,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_datagen=ImageDataGenerator()\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    directory=r\"dataset/animal_data/_test/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=1,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb067b",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e233c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn=Sequential([\n",
    "    Input(shape=(224,224,3)),\n",
    "    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(15, activation='softmax')\n",
    "])\n",
    "model_cnn.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc37ee82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 9s/step - accuracy: 0.0615 - loss: 4.3708 - val_accuracy: 0.0729 - val_loss: 2.7082\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8s/step - accuracy: 0.0657 - loss: 2.7081 - val_accuracy: 0.0685 - val_loss: 2.7082\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 6s/step - accuracy: 0.0677 - loss: 2.7081 - val_accuracy: 0.0685 - val_loss: 2.7082\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 6s/step - accuracy: 0.0558 - loss: 2.7081 - val_accuracy: 0.0729 - val_loss: 2.7081\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 6s/step - accuracy: 0.0688 - loss: 2.7081 - val_accuracy: 0.0729 - val_loss: 2.7081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19af53a66c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn.fit(\n",
    "    train_generator,\n",
    "    epochs=5, validation_data=test_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f4d601",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f7e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model=VGG16() #Import the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b03cdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 175ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_vgg16=model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe8e6224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step\n"
     ]
    }
   ],
   "source": [
    "predictions=decode_predictions(y_pred_vgg16)\n",
    "\n",
    "first_predictions=list()\n",
    "for pred in predictions:\n",
    "    first_predictions.append(pred[0][1])\n",
    "\n",
    "first_predictions=np.array(first_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91be562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three most predicted categories by VGG16 are:\n",
      "ice_bear: 33\n",
      "mushroom: 1\n",
      "brown_bear: 17\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print(\"The three most predicted categories by VGG16 are:\")\n",
    "unique_pred=collections.Counter(first_predictions)\n",
    "for animal in list(unique_pred.keys())[:3]:\n",
    "    print(f\"{animal}: {unique_pred[animal]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21edec0",
   "metadata": {},
   "source": [
    "Transfer learning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a819719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained VGG-16 on ImageNet without the last fully-connected layers\n",
    "model_2=VGG16(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# We do not train the layers in VGG16\n",
    "for layer in model_2.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60ba6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3=Sequential([\n",
    "    model_2,\n",
    "    Flatten(),\n",
    "    Dense(15, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(learning_rate=0.0001, momentum=0.9),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be89e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 12s/step - accuracy: 0.3715 - loss: 12.6176\n",
      "Epoch 2/2\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 12s/step - accuracy: 0.7879 - loss: 3.0149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19afcd41a60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(\n",
    "    train_generator,\n",
    "    epochs=2,\n",
    "    #verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc0c76b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m905/905\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58109s\u001b[0m 64s/step - accuracy: 0.9083 - loss: 1.1416\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dic_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdic_scores\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mAugmented VGG16\u001b[39m\u001b[33m\"\u001b[39m]=model_3.evaluate(test_generator)[\u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m print_results_dic(dic_scores)\n",
      "\u001b[31mNameError\u001b[39m: name 'dic_scores' is not defined"
     ]
    }
   ],
   "source": [
    "dic_scores[\"Augmented VGG16\"]=model_3.evaluate(test_generator)[1]\n",
    "print_results_dic(dic_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml5_deeplearning (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
